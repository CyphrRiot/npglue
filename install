#!/bin/bash
# NPGlue - DeepSeek-R1 Installation Script
# Simple, beautiful, and memory-safe installation

set -e

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

clear
echo -e "${BLUE}╭─────────────────────────────────────────────╮${NC}"
echo -e "${BLUE}│             🚀 NPGlue Installer             │${NC}"
echo -e "${BLUE}│      DeepSeek-R1 + OpenVINO + Goose        │${NC}"
echo -e "${BLUE}╰─────────────────────────────────────────────╯${NC}"
echo
echo -e "${CYAN}This will install everything you need for local AI coding assistance${NC}"
echo

# System checks
echo -e "${BLUE}📋 Checking system requirements...${NC}"
TOTAL_MEM_GB=$(free -g | awk '/^Mem:/{print $2}')
AVAILABLE_GB=$(df . | awk 'NR==2{printf "%.0f", $4/1024/1024}')

if [ "$TOTAL_MEM_GB" -lt 8 ]; then
    echo -e "${RED}❌ Need at least 8GB RAM (found ${TOTAL_MEM_GB}GB)${NC}"
    echo -e "${YELLOW}💡 INT4-AWQ model is memory efficient but still needs 8GB+${NC}"
    exit 1
fi
if [ "$AVAILABLE_GB" -lt 15 ]; then
    echo -e "${RED}❌ Need at least 15GB disk space${NC}"
    exit 1
fi
echo -e "${GREEN}✅ System OK: ${TOTAL_MEM_GB}GB RAM, ${AVAILABLE_GB}GB space${NC}"

# Install system dependencies
echo -e "\n${BLUE}📦 Installing system packages...${NC}"
sudo pacman -S --needed --noconfirm python python-pip base-devel cmake git intel-compute-runtime
echo -e "${GREEN}✅ System packages installed${NC}"

# Create clean Python environment
echo -e "\n${BLUE}🐍 Setting up Python environment...${NC}"
[ -d "openvino-env" ] && rm -rf openvino-env
python -m venv openvino-env
source openvino-env/bin/activate
pip install --upgrade pip wheel

# Install AI packages
echo -e "${BLUE}🤖 Installing AI packages...${NC}"
pip install "openvino>=2024.0.0" "openvino-tokenizers>=2024.0.0" optimum-intel transformers
pip install torch --index-url https://download.pytorch.org/whl/cpu
pip install fastapi uvicorn psutil huggingface-hub
echo -e "${GREEN}✅ AI packages installed${NC}"

# Download model (safe, no loading)
echo -e "\n${BLUE}📥 Downloading DeepSeek-R1 model...${NC}"
mkdir -p models
if [ -f "models/deepseek-r1-int4-awq/DeepSeek-R1-0528-Qwen3-8B-int4_asym-awq-se-ov/openvino_model.bin" ]; then
    echo -e "${GREEN}✅ Model already downloaded${NC}"
else
    echo -e "${CYAN}Downloading optimized INT4-AWQ OpenVINO model...${NC}"
    echo -e "${PURPLE}Using INT4-AWQ: 95%+ quality, faster speed, less RAM${NC}"
    python -c "
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id='Echo9Zulu/DeepSeek-R1-0528-Qwen3-8B-OpenVINO',
    allow_patterns=['DeepSeek-R1-0528-Qwen3-8B-int4_asym-awq-se-ov/*'],
    local_dir='models/deepseek-r1-int4-awq',
    local_dir_use_symlinks=False
)
print('✅ INT4-AWQ model downloaded successfully')
print('🚀 Faster inference with preserved reasoning capability!')
"
fi

# Memory-safe verification (no model loading)
echo -e "\n${BLUE}🧪 Verifying installation...${NC}"
python -c "
import openvino
import transformers
print('✅ OpenVINO:', openvino.__version__)
print('✅ Transformers:', transformers.__version__)
print('✅ Available devices:', openvino.Core().available_devices)
print('✅ All packages working correctly')
"

# Create startup script
cat > start_server.sh << 'EOF'
#!/bin/bash
cd "$(dirname "$0")"
source openvino-env/bin/activate
python server_production.py
EOF
chmod +x start_server.sh

# CPU optimization
echo -e "\n${BLUE}⚡ Optimizing CPU performance...${NC}"
sudo ./boost_cpu.sh

# Beautiful completion message
clear
echo -e "${GREEN}╭─────────────────────────────────────────────╮${NC}"
echo -e "${GREEN}│           🎉 INSTALLATION COMPLETE!         │${NC}"
echo -e "${GREEN}╰─────────────────────────────────────────────╯${NC}"
echo
echo -e "${BLUE}📋 NPGlue is ready! Here's what to do next:${NC}"
echo
echo -e "${YELLOW}1. Start the AI server:${NC}"
echo -e "   ${CYAN}./start_server.sh${NC}"
echo
echo -e "${YELLOW}2. Configure Goose (SAFE method):${NC}"
echo -e "   ${CYAN}# Check if you have existing Goose config:${NC}"
echo -e "   ${CYAN}ls ~/.config/goose/config.yaml${NC}"
echo
echo -e "   ${CYAN}# If NO existing config:${NC}"
echo -e "   ${CYAN}mkdir -p ~/.config/goose${NC}"
echo -e "   ${CYAN}cp goose_config_example.yaml ~/.config/goose/config.yaml${NC}"
echo
echo -e "   ${CYAN}# If you HAVE existing config, add these lines:${NC}"
echo -e "${PURPLE}   provider: openai${NC}"
echo -e "${PURPLE}   model: deepseek-r1-openvino${NC}"
echo -e "${PURPLE}   api_base: http://localhost:8000/v1${NC}"
echo -e "${PURPLE}   api_key: local-key${NC}"
echo -e "   ${CYAN}# (don't overwrite your existing settings!)${NC}"
echo
echo -e "${YELLOW}3. Update Zed settings:${NC}"
echo -e "   ${CYAN}# Add to ~/.config/zed/settings.json:${NC}"
echo -e "${PURPLE}   \"language_models\": {${NC}"
echo -e "${PURPLE}     \"openai\": {${NC}"
echo -e "${PURPLE}       \"api_url\": \"http://localhost:8000/v1\",${NC}"
echo -e "${PURPLE}       \"api_key\": \"local-key\",${NC}"
echo -e "${PURPLE}       \"version\": \"1\",${NC}"
echo -e "${PURPLE}       \"available_models\": [${NC}"
echo -e "${PURPLE}         {${NC}"
echo -e "${PURPLE}           \"name\": \"deepseek-r1-openvino\",${NC}"
echo -e "${PURPLE}           \"display_name\": \"DeepSeek-R1 Local\",${NC}"
echo -e "${PURPLE}           \"max_tokens\": 32768,${NC}"
echo -e "${PURPLE}           \"supports_tools\": true${NC}"
echo -e "${PURPLE}         }${NC}"
echo -e "${PURPLE}       ]${NC}"
echo -e "${PURPLE}     }${NC}"
echo -e "${PURPLE}   }${NC}"
echo -e "   ${CYAN}# Then set default model in agent section:${NC}"
echo -e "${PURPLE}   \"agent\": {${NC}"
echo -e "${PURPLE}     \"default_model\": {${NC}"
echo -e "${PURPLE}       \"provider\": \"openai\",${NC}"
echo -e "${PURPLE}       \"model\": \"deepseek-r1-openvino\"${NC}"
echo -e "${PURPLE}     }${NC}"
echo -e "${PURPLE}   }${NC}"
echo
echo -e "${YELLOW}4. Test the installation:${NC}"
echo -e "   ${CYAN}curl http://localhost:8000/health${NC}"
echo -e "   ${CYAN}python test_installation.py${NC}"
echo
echo -e "${GREEN}📊 Performance expectations:${NC}"
echo -e "   • Speed: ${GREEN}20-30+ tokens/sec${NC} (INT4-AWQ optimized)"
echo -e "   • Memory: ${GREEN}~6-8GB${NC} (reduced from FP16)"
echo -e "   • Model: ${GREEN}DeepSeek-R1 INT4-AWQ (~5.6GB)${NC}"
echo -e "   • Quality: ${GREEN}95%+ of FP16 capability${NC}"
echo
echo -e "${BLUE}💡 Tips:${NC}"
echo -e "   • First generation is slower (warmup)"
echo -e "   • Use 'source openvino-env/bin/activate' to activate environment"
echo -e "   • Server runs on http://localhost:8000"
echo
echo -e "${GREEN}✨ Happy coding with your local AI assistant! ✨${NC}"
